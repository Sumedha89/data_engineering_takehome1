{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame, Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# create spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"nyc-jobs-analysis\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    \"/data_engineering_takehome1/dataset/nyc-jobs.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "df.printSchema()\n",
    "print(\"Total records:\", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: DataFrame) -> DataFrame:\n",
    "    df = df.withColumn(\"Salary Range From\", col(\"Salary Range From\").cast(\"double\"))\\\n",
    "           .withColumn(\"Salary Range To\", col(\"Salary Range To\").cast(\"double\"))\n",
    "\n",
    "    df = df.withColumn(\"avg_salary\", round((col(\"Salary Range From\") + col(\"Salary Range To\"))/2,2))\n",
    "    df = df.withColumn(\"process_date\", to_timestamp(\"Process Date\", \"yyyy-MM-dd'T'HH:mm:ss.SSS\"))\n",
    "    df = df.withColumn(\"process_year\", year(\"process_date\"))\n",
    "\n",
    "    def edu_map(edu_str):\n",
    "        if edu_str is None:\n",
    "            return 0\n",
    "        edu_str = edu_str.lower()\n",
    "        if \"phd\" in edu_str or \"doctor\" in edu_str:\n",
    "            return 5\n",
    "        elif \"master\" in edu_str:\n",
    "            return 4\n",
    "        elif \"bachelor\" in edu_str:\n",
    "            return 3\n",
    "        elif \"associate\" in edu_str:\n",
    "            return 2\n",
    "        elif \"high school\" in edu_str or \"diploma\" in edu_str:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    edu_udf = udf(edu_map, IntegerType())\n",
    "    df = df.withColumn(\"edu_level\", edu_udf(col(\"Minimum Qual Requirements\")))\n",
    "\n",
    "    return df\n",
    "\n",
    "df = feature_engineering(df)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Function: Write CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(df: DataFrame, path: str, mode: str = \"overwrite\", n_partitions: int = 1) -> None:\n",
    "    df.repartition(n_partitions).write.mode(mode).option(\"header\", True).csv(path)\n",
    "    print(f\"Data successfully written to {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KPI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of job postings per category\n",
    "def get_number_of_job_postings_per_category(df: DataFrame, n: int) -> DataFrame:\n",
    "    return df.groupBy(\"Job Category\").agg(sum(\"# Of Positions\").alias(\"total_job_postings\"))\\\n",
    "             .orderBy(\"total_job_postings\", ascending=False).limit(n)\n",
    "\n",
    "# Salary distribution per category\n",
    "def get_salary_distribution_per_category(df: DataFrame) -> DataFrame:\n",
    "    df = df.withColumn(\"avg_salary\", coalesce(col(\"avg_salary\"), lit(0)))\n",
    "    return df.groupBy(\"Job Category\").agg(\n",
    "        round(min(\"avg_salary\"),2).alias(\"min_salary\"),\n",
    "        round(max(\"avg_salary\"),2).alias(\"max_salary\"),\n",
    "        round(avg(\"avg_salary\"),2).alias(\"avg_salary\")\n",
    "    ).orderBy(\"avg_salary\", ascending=False)\n",
    "\n",
    "# Highest salary per agency\n",
    "def get_salary_distribution_per_agency(df: DataFrame) -> DataFrame:\n",
    "    window = Window.partitionBy(\"Agency\").orderBy(col(\"Salary Range To\").desc())\n",
    "    df_rank = df.select(\"Agency\",\"Salary Range To\",\"Business Title\").withColumn(\"rank\", row_number().over(window))\\\n",
    "                 .filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "    return df_rank\n",
    "\n",
    "# Average salary per agency last 2 years\n",
    "def get_salary_per_agency_last2_years(df: DataFrame) -> DataFrame:\n",
    "    df_last2 = df.filter(col(\"process_date\") >= date_sub(current_date(), 365*2))\n",
    "    return df_last2.groupBy(\"Agency\").agg(round(avg(\"avg_salary\"),2).alias(\"avg_salary\"))\\\n",
    "                   .orderBy(\"avg_salary\", ascending=False)\n",
    "\n",
    "# Highest paid skills\n",
    "def get_highest_paid_skill(df: DataFrame, top_n: int) -> DataFrame:\n",
    "    return df.select(\"Salary Range To\",\"Business Title\").distinct().orderBy(col(\"Salary Range To\").desc()).limit(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KPI Computation & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Number of job postings per category\n",
    "job_postings_per_category_df = get_number_of_job_postings_per_category(df, 10)\n",
    "write_csv(job_postings_per_category_df, '/data_engineering_takehome1/jupyter/output/number_of_job_postings_per_category')\n",
    "job_postings_per_category_df.show(10, False)\n",
    "\n",
    "# Visualization\n",
    "job_cat_pd = job_postings_per_category_df.toPandas()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(job_cat_pd['Job Category'], job_cat_pd['total_job_postings'], color='orange')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Job Category')\n",
    "plt.ylabel('Total Job Postings')\n",
    "plt.title('Top 10 Job Postings per Category')\n",
    "plt.show()\n",
    "\n",
    "# 2️⃣ Salary distribution per category\n",
    "salary_distribution_per_category_df = get_salary_distribution_per_category(df)\n",
    "write_csv(salary_distribution_per_category_df, '/data_engineering_takehome1/jupyter/output/salary_distribution_per_category')\n",
    "salary_distribution_per_category_df.show(10, False)\n",
    "\n",
    "# Visualization\n",
    "salary_cat_pd = salary_distribution_per_category_df.toPandas()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(salary_cat_pd['Job Category'], salary_cat_pd['avg_salary'], color='green')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Job Category')\n",
    "plt.ylabel('Average Salary')\n",
    "plt.title('Salary Distribution per Job Category')\n",
    "plt.show()\n",
    "\n",
    "# 3️⃣ Highest salary per agency\n",
    "salary_distribution_per_agency_df = get_salary_distribution_per_agency(df)\n",
    "write_csv(salary_distribution_per_agency_df, '/data_engineering_takehome1/jupyter/output/salary_distribution_per_agency')\n",
    "salary_distribution_per_agency_df.show(10, False)\n",
    "\n",
    "# 4️⃣ Average salary per agency last 2 years\n",
    "salary_per_agency_last2_years_df = get_salary_per_agency_last2_years(df)\n",
    "write_csv(salary_per_agency_last2_years_df, '/data_engineering_takehome1/jupyter/output/salary_per_agency_last2_years')\n",
    "salary_per_agency_last2_years_df.show(10, False)\n",
    "\n",
    "# 5️⃣ Highest paid skills\n",
    "highest_paid_skill_df = get_highest_paid_skill(df, 10)\n",
    "write_csv(highest_paid_skill_df, '/data_engineering_takehome1/jupyter/output/highest_paid_skill')\n",
    "highest_paid_skill_df.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between Higher Degree and Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df.stat.corr(\"edu_level\", \"avg_salary\")\n",
    "print(f\"Pearson correlation between higher degree and salary: {correlation:.3f}\")\n",
    "\n",
    "edu_salary_df = df.groupBy(\"edu_level\").agg(round(avg(\"avg_salary\"),2).alias(\"avg_salary\"))\\\n",
    "                   .orderBy(\"edu_level\")\n",
    "edu_salary_pd = edu_salary_df.toPandas()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(edu_salary_pd['edu_level'], edu_salary_pd['avg_salary'], color='skyblue')\n",
    "plt.xlabel(\"Education Level (1=HS/Diploma, 5=PhD)\")\n",
    "plt.ylabel(\"Average Salary\")\n",
    "plt.title(\"Average Salary vs Higher Degree Level\")\n",
    "plt.xticks([1,2,3,4,5], [\"HS/ Diploma\",\"Associate\",\"Bachelor\",\"Master\",\"PhD\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment & Trigger\n",
    "**Deployment:** Git version control, cloud/on-prem Spark cluster, Python module in S3.  \n",
    "**Trigger:** Client mode for development, cluster mode for production, schedule via cron/Airflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

